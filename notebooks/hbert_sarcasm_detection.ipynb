{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127dd785",
   "metadata": {},
   "source": [
    "#### Hierarchical BERT Architecture for Sarcasm Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614760bf",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "\n",
    "- Here, the paper combined BERT-embeddings along the LSTM & CNN layers. \n",
    "- The model Architecture in paper is also implemented\n",
    "- We used different dataset (sarcasm on reddit) than what is used in the paper\n",
    "- Its a Binary Classification Problem (sarcasti[1] / non-sarcasticc[0])\n",
    "- In Tutorial : Kaggle DS --> API --> Colab, we are doing locally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c3f37",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7092c6",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f53e4",
   "metadata": {},
   "source": [
    "### Data-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd510d7",
   "metadata": {},
   "source": [
    "##### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa582f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T09:59:53.239438Z",
     "iopub.status.busy": "2025-04-21T09:59:53.239214Z",
     "iopub.status.idle": "2025-04-21T09:59:57.576371Z",
     "shell.execute_reply": "2025-04-21T09:59:57.575777Z",
     "shell.execute_reply.started": "2025-04-21T09:59:53.239420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading dataset .csv File\n",
    "df = pd.read_csv(\"/kaggle/input/reddit-sarcasm/sarcasm_train_balanced.csv\") # kaggle\n",
    "# df = pd.read_csv(\"..\\datasets\\sarcasm-reddit\\sarcasm_train_balanced.csv\") # local machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af47a146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T09:59:57.577392Z",
     "iopub.status.busy": "2025-04-21T09:59:57.577125Z",
     "iopub.status.idle": "2025-04-21T09:59:57.601147Z",
     "shell.execute_reply": "2025-04-21T09:59:57.600529Z",
     "shell.execute_reply.started": "2025-04-21T09:59:57.577367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                         NC and NH.  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "\n",
       "  subreddit  score  ups  downs     date          created_utc  \\\n",
       "0  politics      2   -1     -1  2016-10  2016-10-16 23:55:23   \n",
       "1       nba     -4   -1     -1  2016-11  2016-11-01 00:24:10   \n",
       "2       nfl      3    3      0  2016-09  2016-09-22 21:45:37   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24adf22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:02.514707Z",
     "iopub.status.busy": "2025-04-21T10:00:02.514432Z",
     "iopub.status.idle": "2025-04-21T10:00:02.519089Z",
     "shell.execute_reply": "2025-04-21T10:00:02.518261Z",
     "shell.execute_reply.started": "2025-04-21T10:00:02.514688Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows(data-samples) = 1010826 | cols(features) = 10\n"
     ]
    }
   ],
   "source": [
    "# check dataset\n",
    "df.shape # 1010826 rows/data & 10 Features\n",
    "print(f\"rows(data-samples) = {df.shape[0]} | cols(features) = {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143b622",
   "metadata": {},
   "source": [
    "##### Resize Dimentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572cecbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:06.722973Z",
     "iopub.status.busy": "2025-04-21T10:00:06.722376Z",
     "iopub.status.idle": "2025-04-21T10:00:06.734842Z",
     "shell.execute_reply": "2025-04-21T10:00:06.733957Z",
     "shell.execute_reply.started": "2025-04-21T10:00:06.722952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows(data-samples) = 10000 | cols(features) = 2\n"
     ]
    }
   ],
   "source": [
    "# We only use columns 'label' & 'comment' & 30000 Rows/data-samples \n",
    "df = df[:10000] # select first 10,000 Rows\n",
    "#df = df.sample(n=10000, random_state=42) # select 10,000 data purely randomly, 42 for reproduibility\n",
    "df = df[['comment','label']]\n",
    "\n",
    "# Check after resizing dimentions\n",
    "print(f\"rows(data-samples) = {df.shape[0]} | cols(features) = {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f265abc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:10.900203Z",
     "iopub.status.busy": "2025-04-21T10:00:10.899455Z",
     "iopub.status.idle": "2025-04-21T10:00:10.911102Z",
     "shell.execute_reply": "2025-04-21T10:00:10.910339Z",
     "shell.execute_reply.started": "2025-04-21T10:00:10.900179Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows(data-samples) = 9999 | cols(features) = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "comment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() # check for null values\n",
    "df.dropna(inplace=True) # drop null values, inplace=True makes it permanent\n",
    "\n",
    "# Check after dropping null values\n",
    "print(f\"rows(data-samples) = {df.shape[0]} | cols(features) = {df.shape[1]}\")\n",
    "df.isna().sum() # check for null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ac5a2",
   "metadata": {},
   "source": [
    "##### Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ffdfed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:13.724190Z",
     "iopub.status.busy": "2025-04-21T10:00:13.723629Z",
     "iopub.status.idle": "2025-04-21T10:00:13.977200Z",
     "shell.execute_reply": "2025-04-21T10:00:13.976531Z",
     "shell.execute_reply.started": "2025-04-21T10:00:13.724165Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Analysis & Visualisation\n",
    "label_counts = df[\"label\"].value_counts() # label counting\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 3))  # width=6 inches, height=4 inches\n",
    "label_counts.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title(\"Label Distribution\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Data 0 and 1 is balaned now, earlier selecting first 30,000 data was unbalenced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d15ebf",
   "metadata": {},
   "source": [
    "##### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa5cc49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:21.362963Z",
     "iopub.status.busy": "2025-04-21T10:00:21.362665Z",
     "iopub.status.idle": "2025-04-21T10:00:21.388926Z",
     "shell.execute_reply": "2025-04-21T10:00:21.388140Z",
     "shell.execute_reply.started": "2025-04-21T10:00:21.362942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning \n",
    "# Removes numerals /symbols replace with space, keep chars A-Z & a-z, \n",
    "df[\"comment\"] = df[\"comment\"].str.replace(r'[^a-zA-Z\\s]', '', regex=True) # regex = reg exp lib removes unwanted char\n",
    " \n",
    "# Convert to lowercase\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "df[\"comment\"] = df[\"comment\"].apply(lower_case) # each row of df to lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70bb999f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:24.539966Z",
     "iopub.status.busy": "2025-04-21T10:00:24.539402Z",
     "iopub.status.idle": "2025-04-21T10:00:24.547449Z",
     "shell.execute_reply": "2025-04-21T10:00:24.546772Z",
     "shell.execute_reply.started": "2025-04-21T10:00:24.539943Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>0</td>\n",
       "      <td>rpka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>1</td>\n",
       "      <td>no it totally is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>is nvidia falling to amd level bad drivers or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            comment\n",
       "6699      0                                               rpka\n",
       "7532      1                                   no it totally is\n",
       "888       0  is nvidia falling to amd level bad drivers or ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f09e89",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26c9fd",
   "metadata": {},
   "source": [
    "##### BERT-Tokenizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc01e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:27.376483Z",
     "iopub.status.busy": "2025-04-21T10:00:27.376187Z",
     "iopub.status.idle": "2025-04-21T10:00:30.360292Z",
     "shell.execute_reply": "2025-04-21T10:00:30.359636Z",
     "shell.execute_reply.started": "2025-04-21T10:00:27.376462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# importing tokenizer small model 'bert-base-uncased' 12 encoders stacked on each other\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538fd4d",
   "metadata": {},
   "source": [
    "##### Data Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a3bde02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:41.523356Z",
     "iopub.status.busy": "2025-04-21T10:00:41.522674Z",
     "iopub.status.idle": "2025-04-21T10:00:41.527078Z",
     "shell.execute_reply": "2025-04-21T10:00:41.526351Z",
     "shell.execute_reply.started": "2025-04-21T10:00:41.523331Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization Function\n",
    "def tokenize_data(text, max_length=150):\n",
    "    \"\"\"\n",
    "    Param-Var: \n",
    "        Text    : Every row/data from df['comment']\n",
    "        max_len : Max len of sentence we can take , max_len = no of words in each comment/row \n",
    "    \n",
    "    Return : \n",
    "        tokenizer : where we loaded our pre-trained BERT model 'bert-base-uncased'\n",
    "    \"\"\"\n",
    "    \n",
    "    return tokenizer(\n",
    "        text.tolist(), # converting text/comments to list\n",
    "        max_length = max_length,\n",
    "        truncation = True, # if sentence_len > max_len then truncate extra chars of sent so that sentence_len == max_len then\n",
    "        padding = 'max_length', # if sentence_len < max_len then add extra padding so that sentence_len == max_len then\n",
    "        return_tensors = 'np' # 'tf' wont as as train_test_split requires data in np or df format\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de3f59f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:43.866621Z",
     "iopub.status.busy": "2025-04-21T10:00:43.866103Z",
     "iopub.status.idle": "2025-04-21T10:00:46.802085Z",
     "shell.execute_reply": "2025-04-21T10:00:46.801474Z",
     "shell.execute_reply.started": "2025-04-21T10:00:43.866597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# tokenizin Data col 'comment'\n",
    "tokenized_data = tokenize_data(df['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68b4eb92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:49.884446Z",
     "iopub.status.busy": "2025-04-21T10:00:49.884188Z",
     "iopub.status.idle": "2025-04-21T10:00:49.890220Z",
     "shell.execute_reply": "2025-04-21T10:00:49.889538Z",
     "shell.execute_reply.started": "2025-04-21T10:00:49.884429Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[  101, 13316,  1998, ...,     0,     0,     0],\n",
       "       [  101,  2017,  2079, ...,     0,     0,     0],\n",
       "       [  101,  2027,  2020, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  5095,  2305, ...,     0,     0,     0],\n",
       "       [  101, 29420,  2015, ...,     0,     0,     0],\n",
       "       [  101,  2016, 28719, ...,     0,     0,     0]]), 'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]]), 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See tokenized data\n",
    "tokenized_data # the 0s are extra padding we added \n",
    "# \"\"\"\n",
    "# --> Two imp features in tokenized_data\n",
    "# --> 1) input_ids & 2) attention_mask\n",
    "# --> attention_mask :  Binary , 0--> tokens not padded, 1--> tokens padded\n",
    "# --> this info is important as we can understand padded info are not of that much value/relavant comparitiely\n",
    "# --> Unpadded Data wont have any unwanted data hence more relavant \n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f69658",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59d36e4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:53.099588Z",
     "iopub.status.busy": "2025-04-21T10:00:53.099317Z",
     "iopub.status.idle": "2025-04-21T10:00:53.103562Z",
     "shell.execute_reply": "2025-04-21T10:00:53.102784Z",
     "shell.execute_reply.started": "2025-04-21T10:00:53.099568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# X (feature-col/independent-var) tokenized Features , y = Dependent-var (label) raw\n",
    "X = tokenized_data['input_ids'] # X = input data = tokenized_data' input_ids not attn_msk\n",
    "y = df['label'] # y = label from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fcdbcf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:56.434500Z",
     "iopub.status.busy": "2025-04-21T10:00:56.434242Z",
     "iopub.status.idle": "2025-04-21T10:00:56.443032Z",
     "shell.execute_reply": "2025-04-21T10:00:56.442125Z",
     "shell.execute_reply.started": "2025-04-21T10:00:56.434482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test  = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed745935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:00:58.877351Z",
     "iopub.status.busy": "2025-04-21T10:00:58.877069Z",
     "iopub.status.idle": "2025-04-21T10:00:58.882346Z",
     "shell.execute_reply": "2025-04-21T10:00:58.881563Z",
     "shell.execute_reply.started": "2025-04-21T10:00:58.877330Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7999, 150), (2000, 150))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape\n",
    "# ((7999, 150), (2000, 150)) , here 7999, 2000 means rows , but 150 doenst mean Feature cols, rather it means 150 tokens(words) per sentence as we predefined max_lenght=150 earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b606a28",
   "metadata": {},
   "source": [
    "### Build Hierarchical-BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639ecdf",
   "metadata": {},
   "source": [
    "##### Model Architecture Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e40b3bc",
   "metadata": {},
   "source": [
    "- Read and understand the proposed model architecture from the paper.\n",
    "- The model consists of **5 layers**:\n",
    "  1. **(L-1) Sentence Encoding Layer**  \n",
    "     - Encode input data into fixed sized vectors\n",
    "  2. **(L-2) Context Summarization Layer**  \n",
    "     - Convert the indvidual sequence-embeddings from layer-1 to common single-vect\n",
    "     - **Conv1d sentence-summarizer layer** : Paper used Conv2d as their data 1.3B but we use only 30k so we use Conv1d\n",
    "  3. **(L-3) LSTM - Context Encoder Layer**  \n",
    "     - Implement a bi-direc LSTM to capture temporal dependencies from summ-sent layer-2\n",
    "     - Bi-direc LSTM process data in both forward & backward direc, makes capturing v. easy\n",
    "  4. **(L-4) CNN Layer**  \n",
    "     - Extracts local features from encoded context vectors of layer-3\n",
    "     - Try to emphasis significant features relavant to model and \n",
    "     - Give less attn to irrelavant features\n",
    "     - **Kernel-layer**  : We use Conv1d kernels instead of Conv2d, also called cnn-filters\n",
    "     - **Pooling-layer** : Use max pooling to extract imp features\n",
    "  5. **(L-5) FFN / Fully Connected dense-net Layer**  \n",
    "     - Proecess the model to give a final output \n",
    "     - Maps features to final predictions.\n",
    "\n",
    "(L-1) output --> (L-2) output --> (L-3) output --> (L-4) output --> (L-5) output --> predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e192ff3b",
   "metadata": {},
   "source": [
    "##### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50fe039a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:01:23.264522Z",
     "iopub.status.busy": "2025-04-21T10:01:23.264223Z",
     "iopub.status.idle": "2025-04-21T10:01:23.272395Z",
     "shell.execute_reply": "2025-04-21T10:01:23.271669Z",
     "shell.execute_reply.started": "2025-04-21T10:01:23.264493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating the hbert model architecture according to paper\n",
    "class HeirarchicalBERT(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, bert_model, lstm_units, cnn_filters, dense_units):\n",
    "        \"\"\"\n",
    "        Param-Var : \n",
    "            bert_model  : Contains the pre-trained bert model from hugging face\n",
    "            lstm_units  : The number of lstm units after conv1d layer\n",
    "            dense_units : The number of nodes in the FFN / FC-layer\n",
    "        \"\"\"\n",
    "        super(HeirarchicalBERT, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        \n",
    "        # 1. (L-1) Sentence Encoding Layer  \n",
    "        self.dense_sentence = tf.keras.layers.Dense(768, activation='relu') # A dense NN, 768 unit/nodes, bert-base has dimen of 768\n",
    "        \n",
    "        # 2. (L-2) Context Summarization Layer  \n",
    "        self.mean_pooling = tf.keras.layers.GlobalAveragePooling1D() # global avg pooling (1D) layer, convert indv inp embedding to a single vector \n",
    "        \n",
    "        # 3. (L-3) Bi-LSTM - Context Encoder Layer  \n",
    "        self.bilstm_encode = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, return_sequences=True)) # Use bi-directional LSTM, we pass LSTM layer with units to the bi-direc layer\n",
    "        \n",
    "        # 4. (L-4) CNN Layer  \n",
    "        self.conv = tf.keras.layers.Conv1D(cnn_filters, 2, activation='relu') #, 1D not 2D, To capture local features\n",
    "        # Pooling-Layer\n",
    "        self.pool = tf.keras.layers.GlobalMaxPool1D()    \n",
    "         \n",
    "        # 5. (L-5) FFN / Fully Connected dense-net Layer\n",
    "        self.dense_df = tf.keras.layers.Dense(dense_units, activation = 'relu')\n",
    "        \n",
    "        # Output\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation='sigmoid') # 1 unit/node as we are working with binary clf , sarcastic or not sarcastic\n",
    "    \n",
    "        \n",
    "        \n",
    "    # Forward-Pass\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Param-Var :\n",
    "            inputs : tokenized data from \"comment\" col\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # BERT embeddings          \n",
    "        bert_output = self.bert(inputs)[0] # pass input tokens to generate  the BERT embeddings\n",
    "        # (bert_output --> 1> Sentence encoding layer)  \n",
    "        \n",
    "        # 1> Sentence encoding layer  \n",
    "        sentence_encoded = self.dense_sentence(bert_output)\n",
    "        # (sentence_encoded --> 2> Context Summarization Layer)\n",
    "\n",
    "        # 2> Context Summarization Layer \n",
    "        context_summarized = self.mean_pooling(sentence_encoded)\n",
    "        # (context_summarized --> expand_dimen)\n",
    "        \n",
    "        #### Expand Dimentions - Req for LSTM is batch size & timestep\n",
    "        context_summarized = tf.expand_dims(context_summarized, 1) # every 1 time step it will gen 768 dimen single vect\n",
    "        # (expand_dimen(context_summarized) --> 3> LSTM - Context Encoder Layer)\n",
    "        \n",
    "        # 3> LSTM - Context Encoder Layer \n",
    "        context_encoded = self.bilstm_encode(context_summarized)\n",
    "        # (context_encoded --> squeeze Dimen)\n",
    "        \n",
    "        #### Squeeze Dimentions - LSTM Done so squeeze/reduce the expanded dimen\n",
    "        context_encoded_squeezed =  tf.squeeze(context_encoded, axis=1) # 1 = col\n",
    "        # (context_encoded_squeezed --> channel-dimen)\n",
    "        \n",
    "        #### Adding Channel-Dimen to match required input shape by conv layer\n",
    "        context_encoded_expanded = tf.expand_dims(context_encoded_squeezed, axis=-1)\n",
    "        # (channel-dimen (context_encoded_expanded) --> 4> CNN layer) \n",
    "        \n",
    "        # 4> CNN Layer \n",
    "        conv_output  = self.conv(context_encoded_expanded)\n",
    "        pooled_output = self.pool(conv_output)\n",
    "        # (pooled_output --> 5> CNN Layer)\n",
    "        \n",
    "        # 5> FFN / Fully Connected dense-net Layer\n",
    "        dense_output = self.dense_df(pooled_output)\n",
    "        \n",
    "        # Final output-layer\n",
    "        final_output = self.output_layer(dense_output)\n",
    "        \n",
    "        return final_output\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855d5ea",
   "metadata": {},
   "source": [
    "##### Load pre-trained BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bef2e3f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:01:29.253579Z",
     "iopub.status.busy": "2025-04-21T10:01:29.252932Z",
     "iopub.status.idle": "2025-04-21T10:01:32.428561Z",
     "shell.execute_reply": "2025-04-21T10:01:32.427985Z",
     "shell.execute_reply.started": "2025-04-21T10:01:29.253553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792e84da44774b5c80335b6702b873de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745229691.313622      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Loading pretrained BERT model from hugging face\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8a5ab",
   "metadata": {},
   "source": [
    "##### Load Model to GPU - WORKING in Kaggle only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4e859a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:01:35.805862Z",
     "iopub.status.busy": "2025-04-21T10:01:35.805129Z",
     "iopub.status.idle": "2025-04-21T10:01:35.811399Z",
     "shell.execute_reply": "2025-04-21T10:01:35.810605Z",
     "shell.execute_reply.started": "2025-04-21T10:01:35.805830Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n",
      "TensorFlow is using GPU: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745229695.807941      31 gpu_device.cc:2022] Created device /device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "# Check GPU Availability\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Keras uses gpu automaticaclly when availabe \n",
    "print(\"TensorFlow is using GPU:\", tf.test.is_gpu_available()) # Print which device Keras is using"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b86949a",
   "metadata": {},
   "source": [
    "##### Heirarchical BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fda24db1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:01:40.512515Z",
     "iopub.status.busy": "2025-04-21T10:01:40.512273Z",
     "iopub.status.idle": "2025-04-21T10:01:40.541004Z",
     "shell.execute_reply": "2025-04-21T10:01:40.540257Z",
     "shell.execute_reply.started": "2025-04-21T10:01:40.512499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Defining Our hbert model\n",
    "model = HeirarchicalBERT(bert_model, lstm_units=128*2, cnn_filters=64*2, dense_units=32*2) \n",
    "# change hyper-params to evaluate accuracy as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3dac5bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:02:26.158613Z",
     "iopub.status.busy": "2025-04-21T10:02:26.158364Z",
     "iopub.status.idle": "2025-04-21T10:02:26.170458Z",
     "shell.execute_reply": "2025-04-21T10:02:26.169773Z",
     "shell.execute_reply.started": "2025-04-21T10:02:26.158596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44854297",
   "metadata": {},
   "source": [
    "##### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fab0d45e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:02:28.996127Z",
     "iopub.status.busy": "2025-04-21T10:02:28.995844Z",
     "iopub.status.idle": "2025-04-21T10:08:19.950521Z",
     "shell.execute_reply": "2025-04-21T10:08:19.949940Z",
     "shell.execute_reply.started": "2025-04-21T10:02:28.996108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745229794.565158      94 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745229795.593638      93 service.cc:148] XLA service 0x7a4430584c80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745229795.594336      93 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1745229795.763337      93 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 205s 582ms/step - loss: 0.6627 - accuracy: 0.6268\n",
      "Epoch 2/2\n",
      "250/250 [==============================] - 145s 582ms/step - loss: 0.6614 - accuracy: 0.6268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7a44ba910c10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 2, batch_size = 32) \n",
    "# original data = 30,000, test_train_split, train = 80% = 24000, batch_size = 32, 24000/32 = 750 rows in each batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7082738",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e800be49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:08:19.951759Z",
     "iopub.status.busy": "2025-04-21T10:08:19.951481Z",
     "iopub.status.idle": "2025-04-21T10:08:39.030074Z",
     "shell.execute_reply": "2025-04-21T10:08:39.029453Z",
     "shell.execute_reply.started": "2025-04-21T10:08:19.951741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 19s 209ms/step - loss: 0.6549 - accuracy: 0.6375\n",
      "Model Accuracy : 63.749998807907104%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Model Accuracy : {accuracy*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7206888,
     "sourceId": 11496432,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
