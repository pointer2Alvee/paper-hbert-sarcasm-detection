{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127dd785",
   "metadata": {},
   "source": [
    "#### Hierarchical BERT Architecture for Sarcasm Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614760bf",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "\n",
    "- Here, the paper combined BERT-embeddings along the LSTM & CNN layers. \n",
    "- The model Architecture in paper is also implemented\n",
    "- We used different dataset (sarcasm on reddit) than what is used in the paper\n",
    "- Its a Binary Classification Problem (sarcasti[1] / non-sarcasticc[0])\n",
    "- In Tutorial : Kaggle DS --> API --> Colab, we are doing locally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c3f37",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6d7092c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, TFBartModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f53e4",
   "metadata": {},
   "source": [
    "### Data-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd510d7",
   "metadata": {},
   "source": [
    "##### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8fa582f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset .csv File\n",
    "df = pd.read_csv(\"..\\datasets\\sarcasm-reddit\\sarcasm_train_balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "af47a146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                         NC and NH.  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "\n",
       "  subreddit  score  ups  downs     date          created_utc  \\\n",
       "0  politics      2   -1     -1  2016-10  2016-10-16 23:55:23   \n",
       "1       nba     -4   -1     -1  2016-11  2016-11-01 00:24:10   \n",
       "2       nfl      3    3      0  2016-09  2016-09-22 21:45:37   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e24adf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows(data-samples) = 1010826 | cols(features) = 10\n"
     ]
    }
   ],
   "source": [
    "# check dataset\n",
    "df.shape # 1010826 rows/data & 10 Features\n",
    "print(f\"rows(data-samples) = {df.shape[0]} | cols(features) = {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143b622",
   "metadata": {},
   "source": [
    "##### Resize Dimentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "572cecbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows(data-samples) = 30000 | cols(features) = 2\n"
     ]
    }
   ],
   "source": [
    "# We only use columns 'label' & 'comment' & 30000 Rows/data-samples \n",
    "# df = df[:30000] # select first 30,000 Rows\n",
    "df = df.sample(n=30000, random_state=42) # select 30,000 data purely randomly, 42 for reproduibility\n",
    "df = df[['comment','label']]\n",
    "\n",
    "# Check after resizing dimentions\n",
    "print(f\"rows(data-samples) = {df.shape[0]} | cols(features) = {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4f265abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows(data-samples) = 30000 | cols(features) = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "comment    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() # check for null values\n",
    "df.dropna(inplace=True) # drop null values, inplace=True makes it permanent\n",
    "\n",
    "# Check after dropping null values\n",
    "print(f\"rows(data-samples) = {df.shape[0]} | cols(features) = {df.shape[1]}\")\n",
    "df.isna().sum() # check for null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ac5a2",
   "metadata": {},
   "source": [
    "##### Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6ffdfed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Analysis & Visualisation\n",
    "label_counts = df[\"label\"].value_counts() # label counting\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 3))  # width=6 inches, height=4 inches\n",
    "label_counts.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title(\"Label Distribution\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Data 0 and 1 is balaned now, earlier selecting first 30,000 data was unbalenced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d15ebf",
   "metadata": {},
   "source": [
    "##### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aa5cc49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning \n",
    "# Removes numerals /symbols replace with space, keep chars A-Z & a-z, \n",
    "df[\"comment\"] = df[\"comment\"].str.replace(r'[^a-zA-Z\\s]', '', regex=True) # regex = reg exp lib removes unwanted char\n",
    " \n",
    "# Convert to lowercase\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "df[\"comment\"] = df[\"comment\"].apply(lower_case) # each row of df to lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "70bb999f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>794745</th>\n",
       "      <td>but we fixed that with bombs and now their sec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594906</th>\n",
       "      <td>and they promote peaceful cooperation as in syria</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819257</th>\n",
       "      <td>i am right handed and my left arm is stronger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  label\n",
       "794745  but we fixed that with bombs and now their sec...      1\n",
       "594906  and they promote peaceful cooperation as in syria      1\n",
       "819257      i am right handed and my left arm is stronger      0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f09e89",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26c9fd",
   "metadata": {},
   "source": [
    "##### BERT-Tokenizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc01e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2fba6cbf604bd7a0c95747f0c1c3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvee\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\alvee\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9340f7a3fe4d779f8e7b2474559b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2acaced7ed5474eb01ea709f5310ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cf76fa044548158c890bd93fa01a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing tokenizer small model 'bert-base-uncased' 12 encoders stacked on each other\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538fd4d",
   "metadata": {},
   "source": [
    "##### Data Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5a3bde02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization Function\n",
    "def tokenize_data(text, max_length=100):\n",
    "    \"\"\"\n",
    "    Param-Var: \n",
    "        Text    : Every row/data from df['comment']\n",
    "        max_len : Max len of sentence we can take , max_len = no of words in each comment/row \n",
    "    \n",
    "    Return : \n",
    "        tokenizer : where we loaded our pre-trained BERT model 'bert-base-uncased'\n",
    "    \"\"\"\n",
    "    \n",
    "    return tokenizer(\n",
    "        text.tolist(), # converting text/comments to list\n",
    "        max_length = max_length,\n",
    "        truncation = True, # if sentence_len > max_len then truncate extra chars of sent so that sentence_len == max_len then\n",
    "        padding = 'max_length', # if sentence_len < max_len then add extra padding so that sentence_len == max_len then\n",
    "        return_tensors = 'np' # 'tf' wont as as train_test_split requires data in np or df format\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "de3f59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizin Data col 'comment'\n",
    "tokenized_data = tokenize_data(df['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "68b4eb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[ 101, 1998, 2002, ...,    0,    0,    0],\n",
       "       [ 101, 3524, 2017, ...,    0,    0,    0],\n",
       "       [ 101, 1045, 2812, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101, 7929, 2469, ...,    0,    0,    0],\n",
       "       [ 101, 2000, 2115, ...,    0,    0,    0],\n",
       "       [ 101, 2061, 2016, ...,    0,    0,    0]]), 'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]]), 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See tokenized data\n",
    "tokenized_data # the 0s are extra padding we added \n",
    "# \"\"\"\n",
    "# --> Two imp features in tokenized_data\n",
    "# --> 1) input_ids & 2) attention_mask\n",
    "# --> attention_mask :  Binary , 0--> tokens not padded, 1--> tokens padded\n",
    "# --> this info is important as we can understand padded info are not of that much value/relavant comparitiely\n",
    "# --> Unpadded Data wont have any unwanted data hence more relavant \n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f69658",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "59d36e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X (feature-col/independent-var) tokenized Features , y = Dependent-var (label) raw\n",
    "X = tokenized_data['input_ids'] # X = input data = tokenized_data' input_ids not attn_msk\n",
    "y = df['label'] # y = label from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5fcdbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test  = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ed745935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 100), (6000, 100))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape\n",
    "# ((24000, 100), (6000, 100)) , here 24k 6k means rows , but 100 doenst mean Feature cols, rather it means 100 tokens(words) per sentence as we predefined max_lenght=100 earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b606a28",
   "metadata": {},
   "source": [
    "### Build Hierarchical-BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639ecdf",
   "metadata": {},
   "source": [
    "##### Model Architecture Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e40b3bc",
   "metadata": {},
   "source": [
    "- Read and understand the proposed model architecture from the paper.\n",
    "- The model consists of **5 layers**:\n",
    "  1. **(L-1) Sentence Encoding Layer**  \n",
    "     - Encode input data into fixed sized vectors\n",
    "  2. **(L-2) Context Summarization Layer**  \n",
    "     - Convert the indvidual sequence-embeddings from layer-1 to common single-vect\n",
    "     - **Conv1d sentence-summarizer layer** : Paper used Conv2d as their data 1.3B but we use only 30k so we use Conv1d\n",
    "  3. **(L-3) LSTM - Context Encoder Layer**  \n",
    "     - Implement a bi-direc LSTM to capture temporal dependencies from summ-sent layer-2\n",
    "     - Bi-direc LSTM process data in both forward & backward direc, makes capturing v. easy\n",
    "  4. **(L-4) CNN Layer**  \n",
    "     - Extracts local features from encoded context vectors of layer-3\n",
    "     - Try to emphasis significant features relavant to model and \n",
    "     - Give less attn to irrelavant features\n",
    "     - **Kernel-layer**  : We use Conv1d kernels instead of Conv2d, also called cnn-filters\n",
    "     - **Pooling-layer** : Use max pooling to extract imp features\n",
    "  5. **(L-5) FFN / Fully Connected dense-net Layer**  \n",
    "     - Proecess the model to give a final output \n",
    "     - Maps features to final predictions.\n",
    "\n",
    "(L-1) output --> (L-2) output --> (L-3) output --> (L-4) output --> (L-5) output --> predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e192ff3b",
   "metadata": {},
   "source": [
    "##### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the hbert model architecture according to paper\n",
    "class HeirarchicalBERT(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, bert_model, lstm_units, cnn_filters, dense_units):\n",
    "        \"\"\"\n",
    "        Param-Var : \n",
    "            bert_model  : Contains the pre-trained bert model from hugging face\n",
    "            lstm_units  : The number of lstm units after conv1d layer\n",
    "            dense_units : The number of nodes in the FFN / FC-layer\n",
    "        \"\"\"\n",
    "        super(HeirarchicalBERT, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        \n",
    "        # 1. (L-1) Sentence Encoding Layer  \n",
    "        self.dense_sentence = tf.keras.layers.Dense(768, activation='relu') # A dense NN, 768 unit/nodes, bert-base has dimen of 768\n",
    "        \n",
    "        # 2. (L-2) Context Summarization Layer  \n",
    "        self.mean_pooling = tf.keras.layers.GlobalAveragePooling1D() # global avg pooling (1D) layer, convert indv inp embedding to a single vector \n",
    "        \n",
    "        # 3. (L-3) LSTM - Context Encoder Layer  \n",
    "        self.bilstm_encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, return_sequences=True)) # Use bi-directional LSTM, we pass LSTM layer with units to the bi-direc layer\n",
    "        \n",
    "        # 4. (L-4) CNN Layer  \n",
    "        self.conv = tf.keras.layers.Conv1D(cnn_filters=2, activation='relu') #, 1D not 2D, To capture local features\n",
    "        # Pooling-Layer\n",
    "        self.pool = tf.keras.layers.GlobalMaxPool1D()    \n",
    "         \n",
    "        # 5. (L-5) FFN / Fully Connected dense-net Layer\n",
    "        self.dense_df = tf.keras.layers(dense_units, activation = 'relu')\n",
    "        \n",
    "        # Output\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation='sigmoid') # 1 unit/node as we are working with binary clf , sarcastic or not sarcastic\n",
    "        \n",
    "        \n",
    "        # Forward-Pass\n",
    "        def call(self, inputs):\n",
    "            \"\"\"\n",
    "            Param-Var :\n",
    "                inputs : tokenized data from \"comment\" col\n",
    "\n",
    "            \"\"\"\n",
    "            \n",
    "            # BERT embeddings          \n",
    "            bert_output = self.bert(inputs)[0] # pass input tokens to generate  the BERT embeddings\n",
    "            # (bert_output --> 1> Sentence encoding layer)  \n",
    "            \n",
    "            # 1> Sentence encoding layer  \n",
    "            sentence_encoded = self.dense_sentence(bert_output)\n",
    "            # (sentence_encoded --> 2> Context Summarization Layer)\n",
    "\n",
    "            # 2> Context Summarization Layer \n",
    "            context_summarized = self.mean_pooling(sentence_encoded)\n",
    "            # (context_summarized --> expand_dimen)\n",
    "            \n",
    "            #### Expand Dimentions - Req for LSTM is batch size & timestep\n",
    "            context_summarized = tf.expand_dims(context_summarized, 1) # every 1 time step it will gen 768 dimen single vect\n",
    "            # (expand_dimen(context_summarized) --> 3> LSTM - Context Encoder Layer)\n",
    "            \n",
    "            # 3> LSTM - Context Encoder Layer \n",
    "            context_encoded = tf.bilstm_encode(context_summarized)\n",
    "            # (context_encoded --> squeeze Dimen)\n",
    "            \n",
    "            #### Squeeze Dimentions - LSTM Done so squeeze/reduce the expanded dimen\n",
    "            context_encoded_squeezed =  tf.squeeze(context_encoded, axis=1) # 1 = col\n",
    "            # (context_encoded_squeezed --> channel-dimen)\n",
    "            \n",
    "            #### Adding Channel-Dimen to match required input shape by conv layer\n",
    "            context_encoded_expanded = tf.expand_dims(context_encoded_squeezed, axis=-1)\n",
    "            # (channel-dimen (context_encoded_expanded) --> 4> CNN layer) \n",
    "            \n",
    "            # 4> CNN Layer \n",
    "            conv_output  = self.conv(context_encoded_expanded)\n",
    "            pooled_output = self.pool(conv_output)\n",
    "            # (pooled_output --> 5> CNN Layer)\n",
    "            \n",
    "            # 5> FFN / Fully Connected dense-net Layer\n",
    "            dense_output = self.dense_df(pooled_output)\n",
    "            \n",
    "            # Final output-layer\n",
    "            final_output = self.output_layer(dense_output)\n",
    "            \n",
    "            return final_output\n",
    "        \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
